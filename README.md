# 相互学习
图像分类已被当前的社交媒体应用广泛采用。 训练图像分类可以通过全监督分和半监督分类，与全监督分类相比，半监督分类更受关注，因为通常观察到类别标签仅适用于一小部分图像，而社交媒体平台上的大多数图像没有标签。 为此，我们提出了一个两阶段的半监督学习框架。 在第一阶段，我们训练两个自监督模型（SSM）。 一种模型通过预测预变换训练图像的旋转角度来初始化，然后通过标记图像进一步训练。 另一个模型通过对同一样本图像的变换图像的颜色、形状和质量进行一致的预测来初始化，然后通过标记图像进一步训练。 在第二阶段，我们通过深度相互学习融合两个SSM，这利用另一个SSM提供的互补信息来增强两个SSM中的每一个模型，从而可以共享正确的预测。

您可以通过阅读我们的论文（`/Jian_Selfsupervised_Mutual.pdf`）来了解我们的工作，同时我们将论文代码放在`/vgg`文件夹中供您参考。

#### 旋转角度预测任务：
<img width="693" alt="image" src="https://github.com/busitl/mutual/assets/95472784/79964144-e314-437b-9274-72703a38883e">  

图1：自监督模型旋转角度预测的流程。 无监督数据用于训练角度预测模型，从中提取前五个卷积块和随后的 avgPooling 层并将其链接到使用标记数据训练的分类器。 绿色箭头表示未标记的信息流，红色箭头表示标记的信息流。

#### 对比学习任务：
<img width="737" alt="image" src="https://github.com/busitl/mutual/assets/95472784/1b71010b-3701-42b8-81e5-6e159afdcb93">

图2：使用对比损失的自监督模型的流程。 无监督数据用于训练网络，从中提取前五个卷积块和随后的 avgPooling 层并将其链接到使用标记数据训练的分类器。 绿色箭头表示未标记的信息流，红色箭头表示标记的信息流。

#### 多个SSM的相互学习
<img width="723" alt="image" src="https://github.com/busitl/mutual/assets/95472784/6bf649fd-ffce-4fac-99b8-ca1e422501a4">

两个训练好的 SSM 的相互学习。 首先，两个 SSM 生成的概率应通过 KL 散度损失相互匹配。 其次，两个 SSM 的概率应该通过交叉熵损失接近真实标签。 橙色箭头表示训练好的SSM中的数据流，红色箭头表示相互学习部分中的数据流。
